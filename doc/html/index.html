<html>
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Cephes Mathematical Library wrapped for Torch</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

  </head>
  <body>

      <div class="wrapper">
          <header>
          <div id="navcontainer">
          <ul>
<li>
<a href="#toc_0">Cephes Mathematical Functions Library, wrapped for Torch</a>
<ul>
<li>
<a href="#toc_1">Example</a>
<ul>
<li>
<a href="#toc_2">Simple call on a number</a>
</li>
<li>
<a href="#toc_3">Applying to a whole tensor</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">Installation</a>
</li>
<li>
<a href="#toc_5">List of Cephes functions</a>
</li>
<li>
<a href="#toc_6">List of Torch-only functions</a>
<ul>
<li>
<a href="#toc_7">cephes.digamma(x)</a>
</li>
<li>
<a href="#toc_8">cephes.polygamma(m, x)</a>
</li>
<li>
<a href="#toc_9">cephes.betagrad(x, y)</a>
</li>
</ul>
</li>
<li>
<a href="#toc_10">Error Handling</a>
<ul>
<li>
<a href="#toc_11">cephes.setErrorLevel(level)</a>
</li>
<li>
<a href="#toc_12">cephes.getErrorLevel()</a>
</li>
</ul>
</li>
<li>
<a href="#toc_13">Limits</a>
<ul>
<li>
<a href="#toc_14">cephes.nan</a>
</li>
<li>
<a href="#toc_15">cephes.isnan(x)</a>
</li>
<li>
<a href="#toc_16">cephes.isinf(x)</a>
</li>
<li>
<a href="#toc_17">cephes.isfinite(x)</a>
</li>
</ul>
</li>
<li>
<a href="#toc_18">Complex numbers</a>
<ul>
<li>
<a href="#toc_19">cephes.new_cmplx(re, im)</a>
</li>
</ul>
</li>
<li>
<a href="#toc_20">Unit Tests</a>
</li>
<li>
<a href="#toc_21">Direct access to FFI</a>
<ul>
<li>
<a href="#toc_22">cephes.ffi.*</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
          </header>
          <section>
          <h1 id="toc_0">Cephes Mathematical Functions Library, wrapped for Torch</h1>

<p>Provides and wraps the mathematical functions from the <a href="http://www.netlib.org/cephes/">Cephes mathematical library</a>, developed by <a href="http://www.moshier.net">Stephen L. Moshier</a>. This C library provides a <b>lot</b> of mathematical functions. It is used, among many other places, <a href="https://github.com/scipy/scipy/tree/master/scipy/special/cephes">at the heart of SciPy</a>.</p>

<h2 id="toc_1">Example</h2>

<h3 id="toc_2">Simple call on a number</h3>

<p>The wrapped functions can be called from Lua with the same synopsis as their C coutnerpart, and will then return a number, for example:</p>
<div class="highlight"><pre><code class="lua language-lua" data-lang="lua"><span class="nb">require</span> <span class="s1">&#39;</span><span class="s">cephes&#39;</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">cephes</span><span class="p">.</span><span class="n">igam</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1">-- returns a number</span>
</code></pre></div>
<h3 id="toc_3">Applying to a whole tensor</h3>

<p>Our wrappers for cephes functions are vectorized, meaning they can take tensors as arguments, apply the function for each arguments, and return the result into a tensors. Like most torch functions, they also accept an optional Tensor as first argument to store the result into.</p>
<div class="highlight"><pre><code class="lua language-lua" data-lang="lua"><span class="nb">require</span> <span class="s1">&#39;</span><span class="s">cephes&#39;</span>
<span class="c1">-- Call over a whole tensor of parameters</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">cephes</span><span class="p">.</span><span class="n">ndtr</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span> <span class="c1">-- returns a new tensor of same dimension as the input</span>

<span class="c1">-- And it works with several tensor arguments, pairing them map-like</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">cephes</span><span class="p">.</span><span class="n">igam</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1">-- returns a vector of same dimension as x and df</span>

<span class="c1">-- You can mix number and tensors arguments: numbers are automatically expanded</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">cephes</span><span class="p">.</span><span class="n">igam</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1">-- returns a vector of same dimension as y</span>

<span class="c1">-- And of course you can store the result into an existing tensor of the right size</span>
<span class="n">result</span><span class="p">:</span><span class="n">resize</span><span class="p">(</span><span class="n">x</span><span class="p">:</span><span class="n">size</span><span class="p">())</span>
<span class="n">cephes</span><span class="p">.</span><span class="n">igam</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>
<h2 id="toc_4">Installation</h2>

<p>From a terminal:</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">torch-rocks install cephes
</code></pre></div>
<h2 id="toc_5">List of Cephes functions</h2>

<p>See <a href="doubldoc.html">the full list of Cephes double-precision functions</a>. The Torch wrappers respect the same prototypes. </p>

<p><strong>Note</strong>: a few features of the original library have not been wrapped:</p>

<ul>
<li>single-precision functions: due to a few name clashes with their double counterparts, they require a slightly larger effort to wrap. Please <a href="https://github.com/jucor/torch-cephes/issues/new">fill a feature request</a> if you need them.</li>
<li>polynomials with rational coefficients: their names clash with the polynomials with double coefficients. We wrapped the latter, which seem more generally useful, but please <a href="ahttps://github.com/jucor/torch-cephes/issues/new">raise an issue</a>.</li>
</ul>

<h2 id="toc_6">List of Torch-only functions</h2>

<p>Those functions are not part of the original Cephes library</p>

<h3 id="toc_7">cephes.digamma(x)</h3>

<p>Alias for <code>cephes.psi(x)</code></p>

<h3 id="toc_8">cephes.polygamma(m, x)</h3>

<p>The <code>(m+1)</code>-th derivative of the logarithm of the gamma function <a href="http://mathworld.wolfram.com/PolygammaFunction.html">(see MathWorld definition)</a>.</p>

<blockquote>
<p><strong>Input:</strong> </p>

<ul>
<li><code>m</code> : non-negative integer</li>
<li><code>x</code> : real number</li>
</ul>

<p><strong>Returns:</strong> <code>(m+1)</code>-th derivative of the logarithm of the gamma function, evaluated at <code>x</code></p>
</blockquote>

<h3 id="toc_9">cephes.betagrad(x, y)</h3>

<p>The partial-derivative of the beta function, with respect to the first variable.</p>

<blockquote>
<p><strong>Input:</strong> </p>

<ul>
<li><code>x</code> : positive real number</li>
<li><code>y</code> : positive real number</li>
</ul>

<p><strong>Returns:</strong> Partial-derivative of the beta function with respect to the first variable, evaluated at (<code>x</code>, <code>y</code>)</p>
</blockquote>

<h2 id="toc_10">Error Handling</h2>

<p>By default, Torch-Cephes <strong>does not signal any error</strong> (domain, singularity, overflow, underflow, precision). It is as non-intrusive as possible and tries to return a value which is hopefully usable: it might be NaN, it might be inf.</p>

<p>However, the user can ask Cephes to generate lua errors with the following functions.</p>

<h3 id="toc_11">cephes.setErrorLevel(level)</h3>

<p>Sets the level of error reporting.</p>

<blockquote>
<p><strong>Input:</strong>  <code>level</code> : can be any of
  - <code>&#39;off&#39;</code>/<code>0</code> to be entirely quiet
  - <code>&#39;error&#39;</code>/<code>1</code> to issue Lua errors with stack trace
  - <code>&#39;warning&#39;</code>/<code>2</code> to print a warning on stdout</p>

<p><strong>Returns:</strong> None</p>
</blockquote>

<h3 id="toc_12">cephes.getErrorLevel()</h3>

<p>Returns the current level of error reporting, for example to save and restore later.</p>

<blockquote>
<p><strong>Input:</strong>  None</p>

<p><strong>Returns:</strong> integer 0, 1, or 2, representing the current error reporting level, see <code>setErrorLevel()</code></p>
</blockquote>

<h2 id="toc_13">Limits</h2>

<p>Convenience functions to check for finiteness.</p>

<h3 id="toc_14">cephes.nan</h3>

<p>Stands for not a number, clearer alias for <code>0/0</code> </p>

<h3 id="toc_15">cephes.isnan(x)</h3>

<p>Checks if <code>x</code> is not a number.</p>

<blockquote>
<p><strong>Input:</strong> <code>x</code> : any number</p>

<p><strong>Returns:</strong> <code>true</code> if <code>x</code> is <code>cephes.nan</code>, <code>false</code> otherwise</p>
</blockquote>

<h3 id="toc_16">cephes.isinf(x)</h3>

<p>Checks is a number is infinite.</p>

<blockquote>
<p><strong>Input:</strong> <code>x</code> : any number</p>

<p><strong>Returns:</strong>** <code>true</code> if <code>x</code> is <code>math.huge</code> or <code>-math.huge</code> or <code>cephes.nan</code>, <code>false</code> otherwise.</p>
</blockquote>

<h3 id="toc_17">cephes.isfinite(x)</h3>

<p>Checks if a number is finite.</p>

<blockquote>
<p><strong>Input:</strong>  <code>x</code> : any number</p>

<p><strong>Returns:</strong>  <code>not cephes.isinf(x) and not cephes.isnan(x)</code></p>
</blockquote>

<h2 id="toc_18">Complex numbers</h2>

<h3 id="toc_19">cephes.new_cmplx(re, im)</h3>

<blockquote>
<p><strong>Input:</strong> </p>

<ul>
<li><code>re</code> : any number, to initialize the real part</li>
<li><code>im</code> : any number, to initalize the imaginary part</li>
</ul>

<p><strong>Returns:</strong> a pointer to a new Cephes FFI complex number with real part <code>r</code> and imaginary part <code>im</code>.</p>
</blockquote>

<h2 id="toc_20">Unit Tests</h2>

<p>Last but not least, the unit tests are in the folder
<a href="https://github.com/jucor/torch-cephes/tree/master/luasrc/tests"><code>luasrc/tests</code></a>. You can run them from your local clone of the repostiory with:</p>
<div class="highlight"><pre><code class="bash language-bash" data-lang="bash">git clone https://www.github.com/jucor/torch-cephes
find torch-randomkit/luasrc/tests -name <span class="s2">&quot;test*lua&quot;</span> -exec torch <span class="o">{}</span> <span class="se">\;</span>
</code></pre></div>
<p>Those tests will soone be automatically installed with the package, once I sort out a bit of CMake resistance.</p>

<h2 id="toc_21">Direct access to FFI</h2>

<h3 id="toc_22">cephes.ffi.*</h3>

<p>Functions directly accessible at the top of the <code>cephes</code> table are Lua wrappers to the actual C functions from Cephes, with extra error checking. If, for any reason, you want to get rid of this error checking and of a possible overhead, the FFI-wrapper functions can be called directly via <code>cephes.ffi.myfunction()</code> instead of <code>cephes.myfunction()</code>.</p>

          </section>
      </div>
      <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
